{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyK3mn7fecX7"
   },
   "source": [
    "# EpiLearn Demonstration\n",
    "\n",
    "### Created by Wei Jin and Zewen Liu\n",
    "\n",
    "Please feel free to reach out with questions or suggestions: wei.jin@emory.edu and zewen.liu@emory.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1f64vfBexR9"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kYEDdoOecX9"
   },
   "source": [
    "EpiLearn is a Pytorch-based machine learning toolkit for epidemic data modeling and analysis. We provide numerour features including:\n",
    "\n",
    "* Implementation of Epidemic Models\n",
    "* Simulation of Epidemic Spreading\n",
    "* Visualization of Epidemic Data\n",
    "* Unified Pipeline for Epidemic Tasks\n",
    "\n",
    "For more details, please check the github page: [EpiLearn (https://github.com/Emory-Melody/EpiLearn)](https://github.com/Emory-Melody/EpiLearn/tree/main?tab=readme-ov-file).\n",
    "\n",
    "**Remark**: If you like this pacakage, please consider starring us in the GitHub page! Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPu2LsBJe1rj"
   },
   "source": [
    "## Install EpiLearn\n",
    "May take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qv6sHNCee68F",
    "outputId": "27a824c6-75d6-4a40-b4a1-6827ca4deb73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting epilearn==0.0.13\n",
      "  Downloading epilearn-0.0.13.tar.gz (91 kB)\n",
      "     ---------------------------------------- 0.0/92.0 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 30.7/92.0 kB 640.0 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 92.0/92.0 kB 1.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting matplotlib==3.9.1 (from epilearn==0.0.13)\n",
      "  Downloading matplotlib-3.9.1.tar.gz (36.1 MB)\n",
      "     ---------------------------------------- 0.0/36.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.4/36.1 MB 12.6 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 1.6/36.1 MB 21.0 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 2.8/36.1 MB 22.4 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 3.2/36.1 MB 22.9 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 5.2/36.1 MB 25.6 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 6.6/36.1 MB 24.8 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 7.9/36.1 MB 25.2 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 9.2/36.1 MB 25.5 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 10.4/36.1 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------ -------------------------- 11.6/36.1 MB 28.4 MB/s eta 0:00:01\n",
      "     ------------- ------------------------- 12.7/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------- ----------------------- 14.0/36.1 MB 29.8 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.2/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     ----------------- --------------------- 16.5/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------- ------------------- 17.7/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     -------------------- ------------------ 19.0/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     ---------------------- ---------------- 20.4/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 21.7/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 23.0/36.1 MB 28.5 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 24.2/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 25.1/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 26.7/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 27.9/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 29.1/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 30.3/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 31.6/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 32.8/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 34.0/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  35.2/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  36.1/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  36.1/36.1 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------------- 36.1/36.1 MB 21.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [22 lines of output]\n",
      "      + meson setup C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-n4mrgbk3\\matplotlib_513a648ccead4661a82c4abbadba0bd4 C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-n4mrgbk3\\matplotlib_513a648ccead4661a82c4abbadba0bd4\\.mesonpy-jclbyihk -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-n4mrgbk3\\matplotlib_513a648ccead4661a82c4abbadba0bd4\\.mesonpy-jclbyihk\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.6.0\n",
      "      Source dir: C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-n4mrgbk3\\matplotlib_513a648ccead4661a82c4abbadba0bd4\n",
      "      Build dir: C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-n4mrgbk3\\matplotlib_513a648ccead4661a82c4abbadba0bd4\\.mesonpy-jclbyihk\n",
      "      Build type: native build\n",
      "      Program python3 found: YES\n",
      "      Project name: matplotlib\n",
      "      Project version: 3.9.1\n",
      "      WARNING: Failed to activate VS environment: Could not find C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vswhere.exe\n",
      "      \n",
      "      ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']]\n",
      "      The following exception(s) were encountered:\n",
      "      Running `icl \"\"` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `cc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `gcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `clang --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `clang-cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `pgcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      \n",
      "      A full log can be found at C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-n4mrgbk3\\matplotlib_513a648ccead4661a82c4abbadba0bd4\\.mesonpy-jclbyihk\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from torch_geometric) (4.65.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from torch_geometric) (1.24.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from torch_geometric) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from torch_geometric) (2.28.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from torch_geometric) (1.3.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from torch_geometric) (5.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from jinja2->torch_geometric) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from requests->torch_geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from requests->torch_geometric) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from requests->torch_geometric) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from scikit-learn->torch_geometric) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.4.0%2Bcu121.html\n",
      "Requirement already satisfied: torch_scatter in c:\\users\\olarinoyem\\appdata\\local\\miniconda3\\envs\\pyt_env\\lib\\site-packages (2.1.2+pt21cu118)\n"
     ]
    }
   ],
   "source": [
    "# !pip install epilearn==0.0.13\n",
    "# !pip install torch_geometric\n",
    "# !pip install torch_scatter -f https://data.pyg.org/whl/torch-2.4.0%2Bcu121.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7-zZJfxVizoB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting epilearn\n",
      "  Downloading epilearn-0.0.14.tar.gz (93 kB)\n",
      "     ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/93.1 kB ? eta -:--:--\n",
      "     ----------------------------------- ---- 81.9/93.1 kB 1.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 93.1/93.1 kB 1.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting matplotlib==3.9.1 (from epilearn)\n",
      "  Using cached matplotlib-3.9.1.tar.gz (36.1 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [22 lines of output]\n",
      "      + meson setup C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-y1otvdk8\\matplotlib_73935bbafae247bca1777a6e71a79590 C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-y1otvdk8\\matplotlib_73935bbafae247bca1777a6e71a79590\\.mesonpy-xb6izef9 -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-y1otvdk8\\matplotlib_73935bbafae247bca1777a6e71a79590\\.mesonpy-xb6izef9\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.6.0\n",
      "      Source dir: C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-y1otvdk8\\matplotlib_73935bbafae247bca1777a6e71a79590\n",
      "      Build dir: C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-y1otvdk8\\matplotlib_73935bbafae247bca1777a6e71a79590\\.mesonpy-xb6izef9\n",
      "      Build type: native build\n",
      "      Program python3 found: YES\n",
      "      Project name: matplotlib\n",
      "      Project version: 3.9.1\n",
      "      WARNING: Failed to activate VS environment: Could not find C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vswhere.exe\n",
      "      \n",
      "      ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']]\n",
      "      The following exception(s) were encountered:\n",
      "      Running `icl \"\"` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `cc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `gcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `clang --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `clang-cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `pgcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      \n",
      "      A full log can be found at C:\\Users\\olarinoyem\\AppData\\Local\\Temp\\pip-install-y1otvdk8\\matplotlib_73935bbafae247bca1777a6e71a79590\\.mesonpy-xb6izef9\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# exit() # reboot environment\n",
    "!pip install epilearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZFGQFMIecX9"
   },
   "source": [
    "## Building forecasting task with EpiLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxWCzf2PecX9"
   },
   "source": [
    "### Pipeline Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xx14XpxaZ2Ol"
   },
   "source": [
    "#### 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZGiIsO7GecX9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'epilearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# from epilearn.models.SpatialTemporal.STGCN import STGCN\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mepilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mTemporal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GRUModel\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mepilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UniversalDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mepilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'epilearn'"
     ]
    }
   ],
   "source": [
    "# from epilearn.models.SpatialTemporal.STGCN import STGCN\n",
    "from epilearn.models.Temporal import GRUModel\n",
    "from epilearn.data import UniversalDataset\n",
    "from epilearn.utils import transforms\n",
    "from epilearn.tasks import Forecast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVWSy_9aJh8e"
   },
   "source": [
    "#### 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62eVWy2OJgBg"
   },
   "outputs": [],
   "source": [
    "# initialize settings\n",
    "lookback = 12 # inputs size\n",
    "horizon = 3 # predicts size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCieezR6J2IL"
   },
   "source": [
    "#### 2. Dataset Loading\n",
    "\n",
    "To begin with, we need to choose and load data using a UniversalDataset defined by Epilearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsIImKwiJDX5"
   },
   "outputs": [],
   "source": [
    "# # let's use cosine as toy data (we will generate a cosine wave)\n",
    "# num_samples = 1000\n",
    "# x = torch.linspace(0, 2 * torch.pi, num_samples)  # Generate 1000 points between 0 and 2π\n",
    "# cosine_data = torch.cos(x).unsqueeze(1)\n",
    "\n",
    "# dataset = UniversalDataset(x=cosine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPlVnAZvfGkz"
   },
   "outputs": [],
   "source": [
    "# Load Tycho Dataset\n",
    "dataset = UniversalDataset(name='Tycho_v1', root='./tmp_data/')\n",
    "print(dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpFd0PLffH2x"
   },
   "outputs": [],
   "source": [
    "# choose one disease\n",
    "print(\"Chooing:\", dataset.features[1])\n",
    "dataset.x = dataset.x[1].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvM4H-6SfMTX"
   },
   "outputs": [],
   "source": [
    "# Chosen data shape\n",
    "print(dataset.x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxT6lrcQJU9e"
   },
   "source": [
    "#### 3. Transformation\n",
    "\n",
    "Epilearn provides numerous transformations including normalization, seasonal decomposition, converting to frequency domain, etc. The loading of these functions follows similar style to Torch, as shown below.\n",
    "\n",
    "To customize your own transformation, simply add a new class following the style shown in [Transformations](https://vermillion-malasada-a2864e.netlify.app/html/api/utils#transformation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3_iSWe3JE3X"
   },
   "outputs": [],
   "source": [
    "# Adding Transformations\n",
    "transformation = transforms.Compose({\n",
    "                \"features\": [transforms.normalize_feat()]})  # Normalize the features\n",
    "dataset.transforms = transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MwOFThRSejn"
   },
   "outputs": [],
   "source": [
    "transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmVV3pxIM87Y"
   },
   "source": [
    "#### 4. Task Initialization and Model Evaluation\n",
    "Epilearn currently supports two tasks: Forecast and Detection. The Forecast task takes in a UniversalDataset, model prototype and other configurations like lookback window size and the horizon size. The same setting applies to the Detection task. After initializing, you can try functions like `.train_model()` and `.evaluate_model()` to test the models performance on given datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0DeoR8EIV4K"
   },
   "outputs": [],
   "source": [
    "# Initialize Task\n",
    "task = Forecast(prototype=GRUModel,\n",
    "                lookback=lookback,\n",
    "                horizon=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aud2XkPwSvA4"
   },
   "outputs": [],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmqorwl8Z8Yj"
   },
   "source": [
    "For detailed documentation for the `Forecast` class, please refer to https://epilearn-doc.readthedocs.io/en/latest/API/tasks.html#epilearn.tasks.forecast.Forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jveicNINICM"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "result = task.train_model(dataset=dataset,\n",
    "                          loss='mse',    # specificy the loss function to be Mean Squared Error (MSE)\n",
    "                          epochs=5,      # number of training epochs/iterations\n",
    "                          train_rate=0.6,  # 60% is used for training\n",
    "                          val_rate=0.2,    # 20% is used for validation; the rest 20% is for testing\n",
    "                          batch_size=5,  # batch size for training\n",
    "                          device='cpu')  # use CPU for model training; set `device='cuda'` to enable GPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "El4jy2HDNItw"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "evaluation = task.evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEiFpxaUecX-"
   },
   "source": [
    "## Case Study: Forecasting Covid-19 infections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hslxASEOecX-"
   },
   "source": [
    "#### 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMe0rB_xecX-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from epilearn.models.Temporal import GRUModel\n",
    "from epilearn.data import UniversalDataset\n",
    "from epilearn.utils import transforms\n",
    "from epilearn.tasks import Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ua9eq3KyaQGE"
   },
   "source": [
    "\n",
    "#### 1. Configurations\n",
    "\n",
    "# initialize settings\n",
    "lookback = 8 # inputs size\n",
    "horizon = 1 # predicts size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5VJOMaUjtCd"
   },
   "outputs": [],
   "source": [
    "lookback = 8\n",
    "horizon = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyPLdi-iecX_"
   },
   "source": [
    "#### 2. Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IF-X21FNf1Eh"
   },
   "outputs": [],
   "source": [
    "jhu_data = UniversalDataset(name='JHU_covid', root='./tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2aghu12Xrh1"
   },
   "outputs": [],
   "source": [
    "print('Total data:', jhu_data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3ABpFdPecX_"
   },
   "outputs": [],
   "source": [
    "print('Total regions:', jhu_data.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UT1eol1zgD5g"
   },
   "outputs": [],
   "source": [
    "# Choose one region\n",
    "print('Chosen region:', jhu_data.features[100])\n",
    "jhu_data.x = jhu_data.x[100].unsqueeze(1)\n",
    "print('length: ', jhu_data.x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHl2CiU-XnCO"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# visualize the data\n",
    "plt.plot(jhu_data.x)\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('confirmed cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMYpe0IkecYA"
   },
   "source": [
    "#### 3. Apply Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNx4OeOuecYA"
   },
   "outputs": [],
   "source": [
    "# Adding Transformations\n",
    "transformation = transforms.Compose({\n",
    "                \"features\": [transforms.normalize_feat()]})\n",
    "jhu_data.transforms = transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylY4svPKecYA"
   },
   "source": [
    "#### 4. Build Task and Perform Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLvlMt9wecYA"
   },
   "outputs": [],
   "source": [
    "# Initialize Task\n",
    "task = Forecast(prototype=GRUModel,  # add model\n",
    "                lookback=lookback,  # history data length\n",
    "                horizon=horizon,    # future data length\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hjE4rG2ecYA"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "result = task.train_model(dataset=jhu_data,\n",
    "                          loss='mse',      # loss function; using MSE as default\n",
    "                          epochs=100,      # training epochs, we can use more epochs to obtain better performance\n",
    "                          lr=0.01,         # learning rate of the model\n",
    "                          train_rate=0.6,  # 60% is used for training\n",
    "                          val_rate=0.2,    # 20% is used for validation; the rest 20% is for testing\n",
    "                          batch_size=5,\n",
    "                          device='cpu')    # Using CPU could be slow though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gN57cP1ecYA"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "evaluation = task.evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K99_QMQXecYA"
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJodbhouecYA"
   },
   "outputs": [],
   "source": [
    "predictions, groundtruth = task.plot_forecasts(index_range=(0,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_f9-aehAPcW"
   },
   "source": [
    "### Applying various temporal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f55jEz1sAVtY"
   },
   "outputs": [],
   "source": [
    "# To use other popular temporal models, simply import and the change the prototypes in the forecast class\n",
    "from epilearn.models.Temporal import LSTMModel, CNNModel, DlinearModel\n",
    "\n",
    "models = {\"LSTM\": LSTMModel, \"DLinear\": DlinearModel, \"CNN\": CNNModel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDgWGTvgBzBK"
   },
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "  # Loading new prototype\n",
    "  print(f\"Using {name}\")\n",
    "  task.prototype = model\n",
    "  # Training\n",
    "  result = task.train_model(dataset=jhu_data,\n",
    "                            loss='mse',   # loss function; using MSE as default\n",
    "                            epochs=5,    # training epochs\n",
    "                            lr = 0.01,    # learning rate of the model\n",
    "                            train_rate=0.6, # 60% is used for training\n",
    "                            val_rate=0.2, # 20% is used for validation; the rest 20% is for testing\n",
    "                            batch_size=5) # Using CPU could be slow though\n",
    "  # Evaluation\n",
    "  evaluation = task.evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwoF1NUBecYA"
   },
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH0TOO9xecYA"
   },
   "source": [
    "1. Try forecasting other diseases in Tycho Dataset.\n",
    "\n",
    "For more information about the data, please refer to https://github.com/Emory-Melody/EpiLearn/tree/main/datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vEw8_CESnFoO"
   },
   "outputs": [],
   "source": [
    "# Loading more datasets\n",
    "measle_dataset = UniversalDataset(name='Measles', root='./test_downloads/')\n",
    "covid_dataset = UniversalDataset(name='Covid_Brazil', root='./test_downloads/') # (e.g. Covid_'Country'; Supported countries: China, Brazil, Austria, England, France, Italy, Newzealand, Spain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcTUN0VxecYA"
   },
   "source": [
    "## Data Simulation\n",
    "\n",
    "In this section, we provide a tutorial of the simulation methods in EpiLearn. In general, we focus on the simulation of static and dynamic properties including graph structure and node features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbzzZY81ecYA"
   },
   "source": [
    "### 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wGXt3v5HecYB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from epilearn.models.SpatialTemporal import NetSIR\n",
    "from epilearn.models.Temporal import SIR, SIS, SEIR\n",
    "from epilearn.utils import utils, simulation\n",
    "from epilearn import visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VI9EVDeecYB"
   },
   "source": [
    "### Temporal Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c83fbIvdecYB"
   },
   "source": [
    "At the starting time point, we initilize the number of people's states in the region: Suspected, Infected, and Recovered.\n",
    "\n",
    "SIR model assumes the transmission dynamics using the following differential equations:\n",
    "* $ \\frac{dS}{dt} = -\\beta \\frac{SI}{N} $\n",
    "  \n",
    "*  $ \\frac{dI}{dt} = \\beta \\frac{SI}{N} - \\gamma I $\n",
    "  \n",
    "*  $ \\frac{dR}{dt} = \\gamma I $\n",
    "  \n",
    "The $\\beta$ and $\\gamma$ represent **infection rate** and **recovery rate** respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "kAIIairmecYB"
   },
   "outputs": [],
   "source": [
    "data = torch.zeros(3)\n",
    "data.data[0] = 3416 # Initial Suspected\n",
    "data.data[1] = 210  # Initial Infected\n",
    "data.data[2] = 65   # Initial Recovered\n",
    "data = data.float()\n",
    "print(\"Initial States: \", list(data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "y0w_Id5jecYB"
   },
   "outputs": [],
   "source": [
    "# Initialize the model (predicting 100 steps ahead with predefined infection rate and recovery rate)\n",
    "model = SIR(horizon=100, infection_rate=0.1, recovery_rate=0.0384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "31SQ-oyqecYB"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "preds = model(data, steps = None) # steps = None or horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IFkjRU3DecYB"
   },
   "outputs": [],
   "source": [
    "# visualization\n",
    "visualize.plot_series(preds, columns = ['suspected', 'infected', 'recovered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ISt5vlDKlJ1R"
   },
   "outputs": [],
   "source": [
    "### let's add code of all the temporal simulation models we have here:  like sis, seir (2 lines of code)\n",
    "# SIS\n",
    "model = SIS(horizon=100, infection_rate=0.1, recovery_rate=0.0384)\n",
    "# SEIR\n",
    "model = SEIR(horizon=100, infection_rate=0.1, recovery_rate=0.0384, cure_rate=0.05, latency=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juwMz0xhecYB"
   },
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIDez_ZrecYB"
   },
   "source": [
    "1. Get the time of the infection peak.\n",
    "2. Explore the relations between infection rate and the time of the infection peak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSD_n3gFecYB"
   },
   "source": [
    "### Spatial-Temporal Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2u5S1N8ecYC"
   },
   "source": [
    "For Spatial-Temporal Simulation, we initialze a random graph first and then manually set a subset of nodes to be infected while the others are assumed to be suspected.\n",
    "\n",
    "After initialization, we apply a spatial-temporal simulation model: **Network SIR** to get the infection results in the given time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgHgSPsCecYC"
   },
   "source": [
    "### 1. Generate random static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "06GOOfehlceX"
   },
   "outputs": [],
   "source": [
    "# generate random static graph\n",
    "initial_graph = simulation.get_random_graph(num_nodes=25, connect_prob=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dmOUFuHcecYC"
   },
   "outputs": [],
   "source": [
    "initial_states = torch.zeros(25,3) # [S,I,R]\n",
    "initial_states[:, 0] = 1 # set all nodes' initial states to be 'Suspected'\n",
    "# set infected individual: No.3 and No.10\n",
    "initial_states[3, 0] = 0\n",
    "initial_states[3, 1] = 1\n",
    "\n",
    "initial_states[10, 0] = 0\n",
    "initial_states[10, 1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2w2GTYvUecYC"
   },
   "source": [
    "### 2. Initialize NetworkSIR model and perform simulation based on the generated inital graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a1JlFW74ecYC"
   },
   "outputs": [],
   "source": [
    "# Initialize the model and perform simulation\n",
    "model = NetSIR(num_nodes=initial_graph.shape[0], horizon=120, infection_rate=0.05, recovery_rate=0.05) # predicting 120 steps\n",
    "preds = model(initial_states, initial_graph, steps = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWJLxbV5ecYC"
   },
   "source": [
    "### 3. Plot simulation result at a certain time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XTtR25AlecYC"
   },
   "outputs": [],
   "source": [
    "time_step = 17 # visualize a slice of the simulation\n",
    "states = preds.argmax(2)[time_step].detach().numpy() # states at slice t\n",
    "graph = initial_graph.to_sparse().indices().detach().numpy()\n",
    "\n",
    "layout = visualize.plot_graph(states, graph, classes=['Suspected', 'Infected', 'Recovered'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fj1mJO6XecYC"
   },
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWdsR4DtecYC"
   },
   "source": [
    "1. Plot the total number of infections over time. See how the numbers of infected, suscepted and recovered change.\n",
    "2. Get the time of the infection peak.\n",
    "3. Try changing the simulation graph size and connection density. Explore the relations between connectivity and the infection peak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vaxk1t5CledU"
   },
   "source": [
    "## More Simulation Models\n",
    "\n",
    "Beyond the simulation models mentioned above, Epilearn also provides the following:\n",
    "\n",
    "* **Gravity Model**.  The gravity model is used to simulate the interaction between nodes based on their attributes and distance. It is often used in spatial analysis. For example, in epidemic, it can be used to capture the regional contact and transmission patterns invoked by human mobility.\n",
    "  - Check out [our documentation here](https://epilearn-doc.readthedocs.io/en/latest/tutorials/simulation.html#gravity-model)\n",
    "* **Mobility Simulation**. Mobility simulation models the movement of nodes over time, which can represent entities such as people or vehicles in a network.\n",
    "  - Check out [our documentation here](https://epilearn-doc.readthedocs.io/en/latest/tutorials/simulation.html#mobility-simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ia0sGd4zlh2Z"
   },
   "source": [
    "## Modeling Spatial-Temporal Data\n",
    "\n",
    "Additionaly, Epilearn provides support for modeling spatial-temporal data with machine learning tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "DeonpnpYmayP"
   },
   "outputs": [],
   "source": [
    "from epilearn.models.SpatialTemporal import STGCN\n",
    "from epilearn.data import UniversalDataset\n",
    "from epilearn.utils import transforms\n",
    "from epilearn.tasks.forecast import Forecast\n",
    "\n",
    "\n",
    "# initialize settings\n",
    "lookback = 12 # inputs size\n",
    "horizon = 3 # predicts size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6AjiuAx1mwOO"
   },
   "outputs": [],
   "source": [
    "\n",
    "# load toy dataset\n",
    "dataset = UniversalDataset()\n",
    "dataset.load_toy_dataset()\n",
    "# Adding Transformations\n",
    "transformation = transforms.Compose({\n",
    "                \"features\": [transforms.normalize_feat()],\n",
    "                \"graph\": [transforms.normalize_adj()]})\n",
    "dataset.transforms = transformation\n",
    "\n",
    "# Initialize Task\n",
    "task = Forecast(prototype=STGCN,\n",
    "                dataset=None,\n",
    "                lookback=lookback,\n",
    "                horizon=horizon,\n",
    "                device='cpu')\n",
    "\n",
    "# Training\n",
    "result = task.train_model(dataset=dataset,\n",
    "                          loss='mse',\n",
    "                          epochs=2,\n",
    "                          batch_size=5,\n",
    "                          permute_dataset=True)\n",
    "# Evaluation\n",
    "evaluation = task.evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrYAeoELHS7Q"
   },
   "source": [
    "## A Breif Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hyd4jAd0HdZR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from epilearn.models.Temporal import GRUModel\n",
    "from epilearn.data import UniversalDataset\n",
    "from epilearn.utils import transforms\n",
    "from epilearn.tasks import Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC7ctS9lJqrj"
   },
   "source": [
    "With Epilearn, we only need **5 lines of code**!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Y4bprLhlH9w5"
   },
   "outputs": [],
   "source": [
    "measle_dataset = UniversalDataset(name='Measles', root='./test_downloads/')\n",
    "measle_dataset.transforms = transforms.Compose({ \"features\": [transforms.normalize_feat()]})\n",
    "task = Forecast(prototype=GRUModel, lookback=12, horizon=1)\n",
    "result = task.train_model(dataset=measle_dataset, loss='mse', epochs=10, lr=0.01, batch_size=5, device='cpu')\n",
    "evaluation = task.evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pyt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
