{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Parameter\n",
    "\n",
    "# Set seaborn style for better aesthetics\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility\n",
    "RANDOM_SEED = 123\n",
    "def seed_torch(seed=RANDOM_SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch()\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "num_nodes = 7\n",
    "num_features = 5  # ['new_confirmed', 'new_deceased', 'newAdmissions', 'hospitalCases', 'covidOccupiedMVBeds']\n",
    "num_timesteps_input = 14\n",
    "num_timesteps_output = 7\n",
    "k = 8\n",
    "hidA = 64\n",
    "hidR = 40\n",
    "hidP = 1\n",
    "n_layer = 2\n",
    "dropout = 0.5\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "threshold_distance = 300  # in km\n",
    "\n",
    "# %%\n",
    "# Reference dataset for correction\n",
    "REFERENCE_COORDINATES = {\n",
    "    \"East of England\": (52.1766, 0.425889),\n",
    "    \"Midlands\": (52.7269, -1.458210),\n",
    "    \"London\": (51.4923, -0.308660),\n",
    "    \"South East\": (51.4341, -0.969570),\n",
    "    \"South West\": (50.8112, -3.633430),\n",
    "    \"North West\": (53.8981, -2.657550),\n",
    "    \"North East and Yorkshire\": (54.5378, -2.180390),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "num_nodes = 7\n",
    "num_features = 5  # ['new_confirmed', 'new_deceased', 'newAdmissions', 'hospitalCases', 'covidOccupiedMVBeds']\n",
    "num_timesteps_input = 14\n",
    "num_timesteps_output = 7\n",
    "k = 8\n",
    "hidA = 64\n",
    "hidR = 40\n",
    "hidP = 1\n",
    "n_layer = 2\n",
    "dropout = 0.5\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "threshold_distance = 300  # in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference dataset for correction\n",
    "REFERENCE_COORDINATES = {\n",
    "    \"East of England\": (52.1766, 0.425889),\n",
    "    \"Midlands\": (52.7269, -1.458210),\n",
    "    \"London\": (51.4923, -0.308660),\n",
    "    \"South East\": (51.4341, -0.969570),\n",
    "    \"South West\": (50.8112, -3.633430),\n",
    "    \"North West\": (53.8981, -2.657550),\n",
    "    \"North East and Yorkshire\": (54.5378, -2.180390),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def load_and_correct_data(data, reference_coordinates):\n",
    "    # Correct latitude and longitude based on reference coordinates\n",
    "    for region, coords in reference_coordinates.items():\n",
    "        data.loc[data['areaName'] == region, ['latitude', 'longitude']] = coords\n",
    "\n",
    "    # Display unique latitudes and longitudes for verification\n",
    "    unique_latitudes = data['latitude'].unique()\n",
    "    unique_longitudes = data['longitude'].unique()\n",
    "    print(\"Unique latitudes:\", unique_latitudes)\n",
    "    print(\"Unique longitudes:\", unique_longitudes)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHSRegionDataset class\n",
    "class NHSRegionDataset(Dataset):\n",
    "    def __init__(self, data, num_timesteps_input, num_timesteps_output, transform=None):\n",
    "        self.data = data.copy()\n",
    "        self.num_timesteps_input = num_timesteps_input\n",
    "        self.num_timesteps_output = num_timesteps_output\n",
    "        self.transform = transform\n",
    "\n",
    "        # Sort data by region and date\n",
    "        self.data.sort_values(['areaName', 'date'], inplace=True)\n",
    "        self.regions = self.data['areaName'].unique()\n",
    "        self.num_nodes = len(self.regions)\n",
    "        self.region_to_idx = {region: idx for idx, region in enumerate(self.regions)}\n",
    "        self.data['region_idx'] = self.data['areaName'].map(self.region_to_idx)\n",
    "\n",
    "        # Features to include\n",
    "        self.features = ['new_confirmed', 'new_deceased', 'newAdmissions', 'hospitalCases', 'covidOccupiedMVBeds']\n",
    "\n",
    "        # Pivot data to create a time-series matrix\n",
    "        # This will create a multi-level column index: (feature, region_idx)\n",
    "        self.pivot = self.data.pivot(index='date', columns='region_idx', values=self.features)\n",
    "\n",
    "        # Fill missing values\n",
    "        self.pivot.ffill(inplace=True)\n",
    "        self.pivot.fillna(0, inplace=True)\n",
    "\n",
    "        # Convert to numpy array and reshape\n",
    "        # The pivot will have shape (num_dates, num_nodes * num_features)\n",
    "        self.feature_array = self.pivot.values\n",
    "        self.num_features = len(self.features)\n",
    "        self.num_nodes = len(self.regions)\n",
    "        self.num_dates = self.feature_array.shape[0]\n",
    "        self.feature_array = self.feature_array.reshape(self.num_dates, self.num_nodes, self.num_features)\n",
    "\n",
    "        # Validate population consistency across each region\n",
    "        populations = self.data.groupby('areaName')['population'].unique()\n",
    "        inconsistent_populations = populations[populations.apply(len) > 1]\n",
    "        if not inconsistent_populations.empty:\n",
    "            raise ValueError(f\"Inconsistent population values found in regions: {inconsistent_populations.index.tolist()}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_dates - self.num_timesteps_input - self.num_timesteps_output + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.feature_array[idx:idx + self.num_timesteps_input]  # Input sequence\n",
    "        Y = self.feature_array[idx + self.num_timesteps_input:idx + self.num_timesteps_input + self.num_timesteps_output, :, 4]  # Target variable: 'covidOccupiedMVBeds'\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "            Y = self.transform(Y)\n",
    "\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define adjacency matrix computation\n",
    "def compute_geographic_adjacency(regions, latitudes, longitudes, threshold=threshold_distance):\n",
    "    \"\"\"\n",
    "    Computes the geographic adjacency matrix based on the haversine distance between regions.\n",
    "    \n",
    "    Args:\n",
    "        regions (list): List of region names.\n",
    "        latitudes (list): List of latitudes corresponding to regions.\n",
    "        longitudes (list): List of longitudes corresponding to regions.\n",
    "        threshold (float): Distance threshold in kilometers to consider adjacency.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Adjacency matrix of shape (num_nodes, num_nodes).\n",
    "    \"\"\"\n",
    "    def haversine(lat1, lon1, lat2, lon2):\n",
    "        # Convert decimal degrees to radians\n",
    "        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "        # Haversine formula\n",
    "        dlat = lat2 - lat1 \n",
    "        dlon = lon2 - lon1 \n",
    "        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "        c = 2 * asin(sqrt(a)) \n",
    "        r = 6371  # Radius of earth in kilometers\n",
    "        return c * r\n",
    "\n",
    "    num_nodes = len(regions)\n",
    "    adj_matrix = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i == j:\n",
    "                adj_matrix[i][j] = 1  # Self-loop\n",
    "            elif adj_matrix[i][j] == 0:\n",
    "                distance = haversine(latitudes[i], longitudes[i], latitudes[j], longitudes[j])\n",
    "                if distance <= threshold:\n",
    "                    adj_matrix[i][j] = 1\n",
    "                    adj_matrix[j][i] = 1  # Symmetry\n",
    "\n",
    "    return torch.tensor(adj_matrix, dtype=torch.float32)\n",
    "\n",
    "# %%\n",
    "# Define Laplace Matrix computation\n",
    "def getLaplaceMat(batch_size, m, adj):\n",
    "    \"\"\"\n",
    "    Computes the Laplacian matrix for the graph convolution.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): Number of graphs in the batch.\n",
    "        m (int): Number of nodes in each graph.\n",
    "        adj (torch.Tensor): Adjacency matrix of shape (batch_size, m, m).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Laplacian matrix of shape (batch_size, m, m).\n",
    "    \"\"\"\n",
    "    i_mat = torch.eye(m).to(adj.device).unsqueeze(0).expand(batch_size, m, m)\n",
    "    o_mat = torch.ones(m).to(adj.device).unsqueeze(0).expand(batch_size, m, m)\n",
    "    adj = torch.where(adj > 0, o_mat, adj)\n",
    "\n",
    "    d_mat_in = torch.sum(adj, dim=1)\n",
    "    d_mat_out = torch.sum(adj, dim=2)\n",
    "    d_mat = d_mat_out.unsqueeze(2) + 1e-12\n",
    "    d_mat = torch.pow(d_mat, -1)\n",
    "    d_mat = i_mat * d_mat\n",
    "\n",
    "    laplace_mat = torch.bmm(d_mat, adj)\n",
    "    return laplace_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model components\n",
    "\n",
    "class GraphConvLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(in_features, out_features))\n",
    "        self.act = nn.ELU()\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "            stdv = 1.0 / math.sqrt(self.bias.size(0))\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, feature, adj):\n",
    "        support = torch.matmul(feature, self.weight)\n",
    "        output = torch.matmul(adj, support)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            return self.act(output + self.bias)\n",
    "        else:\n",
    "            return self.act(output)\n",
    "\n",
    "class GraphLearner(nn.Module):\n",
    "    def __init__(self, hidden_dim, tanhalpha=1):\n",
    "        super(GraphLearner, self).__init__()\n",
    "        self.hid = hidden_dim\n",
    "        self.linear1 = nn.Linear(self.hid, self.hid)\n",
    "        self.linear2 = nn.Linear(self.hid, self.hid)\n",
    "        self.alpha = tanhalpha\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        \"\"\"\n",
    "        Learns the adjacency matrix based on node embeddings.\n",
    "\n",
    "        Args:\n",
    "            embedding (torch.Tensor): Node embeddings of shape (batch_size, num_nodes, hidden_dim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Learned adjacency matrix of shape (batch_size, num_nodes, num_nodes).\n",
    "        \"\"\"\n",
    "        nodevec1 = self.linear1(embedding)\n",
    "        nodevec2 = self.linear2(embedding)\n",
    "        nodevec1 = self.alpha * nodevec1\n",
    "        nodevec2 = self.alpha * nodevec2\n",
    "        nodevec1 = torch.tanh(nodevec1)\n",
    "        nodevec2 = torch.tanh(nodevec2)\n",
    "\n",
    "        adj = torch.bmm(nodevec1, nodevec2.transpose(1, 2)) - torch.bmm(nodevec2, nodevec1.transpose(1, 2))\n",
    "        adj = self.alpha * adj\n",
    "        adj = torch.relu(torch.tanh(adj))\n",
    "        return adj\n",
    "\n",
    "class ConvBranch(nn.Module):\n",
    "    def __init__(self, m, in_channels, out_channels, kernel_size, dilation_factor=2, hidP=1, isPool=True):\n",
    "        super(ConvBranch, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, 1), dilation=(dilation_factor, 1))\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.isPool = isPool\n",
    "        if self.isPool and hidP is not None:\n",
    "            self.pooling = nn.AdaptiveMaxPool2d((hidP, m))\n",
    "        self.activate = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        if self.isPool and hasattr(self, 'pooling'):\n",
    "            x = self.pooling(x)\n",
    "        x = x.view(batch_size, -1, x.size(-1))\n",
    "        x = self.activate(x)\n",
    "        return x\n",
    "\n",
    "class RegionAwareConv(nn.Module):\n",
    "    def __init__(self, nfeat, P, m, k, hidP, dilation_factor=2):\n",
    "        super(RegionAwareConv, self).__init__()\n",
    "        self.conv_l1 = ConvBranch(m=m, in_channels=nfeat, out_channels=k, kernel_size=3, dilation_factor=1, hidP=hidP)\n",
    "        self.conv_l2 = ConvBranch(m=m, in_channels=nfeat, out_channels=k, kernel_size=5, dilation_factor=1, hidP=hidP)\n",
    "        self.conv_p1 = ConvBranch(m=m, in_channels=nfeat, out_channels=k, kernel_size=3, dilation_factor=dilation_factor, hidP=hidP)\n",
    "        self.conv_p2 = ConvBranch(m=m, in_channels=nfeat, out_channels=k, kernel_size=5, dilation_factor=dilation_factor, hidP=hidP)\n",
    "        self.conv_g = ConvBranch(m=m, in_channels=nfeat, out_channels=k, kernel_size=P, dilation_factor=1, hidP=None, isPool=False)\n",
    "        self.activate = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Applies multiple convolution branches to extract local, periodic, and global features.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, num_features, P, m).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after convolution and activation, shape (batch_size, k*4, m).\n",
    "        \"\"\"\n",
    "        x_l1 = self.conv_l1(x)\n",
    "        x_l2 = self.conv_l2(x)\n",
    "        x_local = torch.cat([x_l1, x_l2], dim=1)\n",
    "\n",
    "        x_p1 = self.conv_p1(x)\n",
    "        x_p2 = self.conv_p2(x)\n",
    "        x_period = torch.cat([x_p1, x_p2], dim=1)\n",
    "\n",
    "        x_global = self.conv_g(x)\n",
    "\n",
    "        x = torch.cat([x_local, x_period, x_global], dim=1)\n",
    "        if x.size(1) > 0:\n",
    "            x = x.permute(0, 2, 1)\n",
    "        x = self.activate(x)\n",
    "        return x\n",
    "\n",
    "class EpiGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted Epidemiological Graph Neural Network (EpiGNN) for Hospitalization Prediction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_nodes : int\n",
    "        Number of nodes in the graph (e.g., 7 NHS regions).\n",
    "    num_features : int\n",
    "        Number of features per node per timestep.\n",
    "    num_timesteps_input : int\n",
    "        Number of timesteps considered for each input sample.\n",
    "    num_timesteps_output : int\n",
    "        Number of output timesteps to predict.\n",
    "    k : int, optional\n",
    "        Number of local neighborhoods to consider in the graph learning layer. Default: 8.\n",
    "    hidA : int, optional\n",
    "        Dimension of attention in the model. Default: 64.\n",
    "    hidR : int, optional\n",
    "        Dimension of hidden layers in the recurrent neural network part. Default: 40.\n",
    "    hidP : int, optional\n",
    "        Dimension of positional encoding in the model. Default: 1.\n",
    "    n_layer : int, optional\n",
    "        Number of layers in the graph neural network. Default: 2.\n",
    "    dropout : float, optional\n",
    "        Dropout rate for regularization during training to prevent overfitting. Default: 0.5.\n",
    "    device : str, optional\n",
    "        The device (cpu or gpu) on which the model will be run. Default: 'cpu'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        A tensor of shape (batch_size, num_timesteps_output, num_nodes), representing the predicted ICU bed usage for each node over future timesteps.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                num_nodes, \n",
    "                num_features, \n",
    "                num_timesteps_input,\n",
    "                num_timesteps_output, \n",
    "                k=8, \n",
    "                hidA=64, \n",
    "                hidR=40, \n",
    "                hidP=1, \n",
    "                n_layer=2, \n",
    "                dropout=0.5, \n",
    "                device='cpu'):\n",
    "        super(EpiGNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.nfeat = num_features\n",
    "        self.m = num_nodes\n",
    "        self.w = num_timesteps_input\n",
    "        self.droprate = dropout\n",
    "        self.hidR = hidR\n",
    "        self.hidA = hidA\n",
    "        self.hidP = hidP\n",
    "        self.k = k\n",
    "        self.n = n_layer\n",
    "        self.dropout_layer = nn.Dropout(self.droprate)\n",
    "\n",
    "        # Feature embedding\n",
    "        self.backbone = RegionAwareConv(nfeat=num_features, P=self.w, m=self.m, k=self.k, hidP=self.hidP)\n",
    "\n",
    "        # Global transmission risk encoding\n",
    "        self.WQ = nn.Linear(self.hidR, self.hidA)\n",
    "        self.WK = nn.Linear(self.hidR, self.hidA)\n",
    "        self.leakyrelu = nn.LeakyReLU(inplace=True)\n",
    "        self.t_enc = nn.Linear(1, self.hidR)\n",
    "\n",
    "        # Local transmission risk encoding\n",
    "        self.s_enc = nn.Linear(1, self.hidR)\n",
    "\n",
    "        # External resources (if any, optional)\n",
    "        self.external_parameter = nn.Parameter(torch.FloatTensor(self.m, self.m), requires_grad=True)\n",
    "        nn.init.xavier_uniform_(self.external_parameter)\n",
    "\n",
    "        # Graph Generator and GCN\n",
    "        self.d_gate = nn.Parameter(torch.FloatTensor(self.m, self.m), requires_grad=True)\n",
    "        nn.init.xavier_uniform_(self.d_gate)\n",
    "        self.graphGen = GraphLearner(self.hidR)\n",
    "        self.GNNBlocks = nn.ModuleList([GraphConvLayer(in_features=self.hidR, out_features=self.hidR) for _ in range(self.n)])\n",
    "\n",
    "        # Prediction layer\n",
    "        self.output = nn.Linear(self.hidR * 2, num_timesteps_output)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)  # Best practice\n",
    "            else:\n",
    "                stdv = 1.0 / math.sqrt(p.size(0))\n",
    "                p.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, X, adj, states=None, dynamic_adj=None, index=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the adapted EpiGNN model for Hospitalization Prediction.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch.Tensor\n",
    "            Input features tensor with shape (batch_size, num_timesteps_input, num_nodes, num_features).\n",
    "        adj : torch.Tensor\n",
    "            Static adjacency matrix with shape (num_nodes, num_nodes) or (batch_size, num_nodes, num_nodes).\n",
    "        states : torch.Tensor, optional\n",
    "            Current state variables tensor (if applicable). Default: None.\n",
    "        dynamic_adj : torch.Tensor, optional\n",
    "            Dynamic adjacency matrix (if applicable). Default: None.\n",
    "        index : torch.Tensor, optional\n",
    "            Indices for external resources (if applicable). Default: None.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The output tensor of shape (batch_size, num_timesteps_output, num_nodes),\n",
    "            representing the predicted ICU bed usage for each node over future timesteps.\n",
    "        \"\"\"\n",
    "        adj = adj.bool().float()\n",
    "        batch_size = X.size(0)  # batch_size, T, N, F\n",
    "\n",
    "        # Ensure adj has batch dimension\n",
    "        if adj.dim() == 2:\n",
    "            adj = adj.unsqueeze(0).repeat(batch_size, 1, 1)  # Shape: (batch_size, m, m)\n",
    "\n",
    "        # Step 1: Use multi-scale convolution to extract feature embedding (RegionAwareConv)\n",
    "        # Reshape X to (batch_size, num_features, P, m) where P = num_timesteps_input, m = num_nodes\n",
    "        X_reshaped = X.permute(0, 3, 1, 2)  # (batch_size, F, T, N)\n",
    "        temp_emb = self.backbone(X_reshaped)  # Shape: (batch_size, hidR, m)\n",
    "\n",
    "        # Step 2: Generate global transmission risk encoding\n",
    "        query = self.WQ(temp_emb)  # Shape: (batch_size, m, hidA)\n",
    "        query = self.dropout_layer(query)\n",
    "        key = self.WK(temp_emb)    # Shape: (batch_size, m, hidA)\n",
    "        key = self.dropout_layer(key)\n",
    "        attn = torch.bmm(query, key.transpose(1, 2))  # Shape: (batch_size, m, m)\n",
    "        attn = F.normalize(attn, dim=-1, p=2, eps=1e-12)  # Normalize\n",
    "        attn = torch.sum(attn, dim=-1, keepdim=True)      # Shape: (batch_size, m, 1)\n",
    "        \n",
    "        # Optional: Verify the shape\n",
    "        print(f\"attn shape before t_enc: {attn.shape}\")  # Should output: torch.Size([32, 7, 1])\n",
    "        \n",
    "        t_enc = self.t_enc(attn)                         # Shape: (batch_size, m, hidR)\n",
    "        t_enc = self.dropout_layer(t_enc)\n",
    "\n",
    "        # Step 3: Generate local transmission risk encoding\n",
    "        d = torch.sum(adj, dim=1).unsqueeze(1)            # Shape: (batch_size, 1, m)\n",
    "        s_enc = self.s_enc(d)                             # Shape: (batch_size, m, hidR)\n",
    "        s_enc = self.dropout_layer(s_enc)\n",
    "\n",
    "        # Step 4: Three embedding fusion\n",
    "        feat_emb = temp_emb + t_enc + s_enc  \n",
    "\n",
    "        # Step 5: Region-Aware Graph Learner\n",
    "        # Load external resource if available (optional)\n",
    "        if self.external_parameter is not None and index is not None:\n",
    "            extra_adj_list = []\n",
    "            zeros_mt = torch.zeros((self.m, self.m)).to(adj.device)\n",
    "            for i in range(batch_size):\n",
    "                offset = 20\n",
    "                if i - offset >= 0:\n",
    "                    idx = i - offset\n",
    "                    extra_adj_list.append(self.external_parameter[index[i], :, :].unsqueeze(0))\n",
    "                else:\n",
    "                    extra_adj_list.append(zeros_mt.unsqueeze(0))\n",
    "            extra_info = torch.cat(extra_adj_list, dim=0)  # Shape: (batch_size, m, m)\n",
    "            external_info = torch.mul(self.external_parameter, extra_info)\n",
    "            external_info = F.relu(external_info)\n",
    "        else:\n",
    "            external_info = 0\n",
    "\n",
    "        # Apply Graph Learner to generate a graph\n",
    "        # Adjusted to handle batched adjacency matrices\n",
    "        d_mat = torch.bmm(torch.sum(adj, dim=1).unsqueeze(2), torch.sum(adj, dim=1).unsqueeze(1))  # Shape: (batch_size, 1, 1)\n",
    "        d_mat = torch.mul(self.d_gate, d_mat)                                                # Shape: (batch_size, m, m)\n",
    "        d_mat = torch.sigmoid(d_mat)                                                         # Shape: (batch_size, m, m)\n",
    "        spatial_adj = torch.mul(d_mat, adj)                                                  # Shape: (batch_size, m, m)\n",
    "        learned_adj = self.graphGen(feat_emb)                                                # Shape: (batch_size, m, m)\n",
    "\n",
    "        # If additional information, fuse\n",
    "        if external_info != 0:\n",
    "            adj = learned_adj + spatial_adj + external_info\n",
    "        else:\n",
    "            adj = learned_adj + spatial_adj\n",
    "\n",
    "        # Get Laplace adjacency matrix\n",
    "        laplace_adj = getLaplaceMat(batch_size, self.m, adj)\n",
    "\n",
    "        # Step 6: Graph Convolution Network\n",
    "        node_state = feat_emb                                       # Shape: (batch_size, m, hidR)\n",
    "        node_state_list = []\n",
    "        for layer in self.GNNBlocks:\n",
    "            node_state = layer(node_state, laplace_adj)           # Shape: (batch_size, m, hidR)\n",
    "            node_state = self.dropout_layer(node_state)\n",
    "            node_state_list.append(node_state)\n",
    "        \n",
    "        # Concatenate node states from all GNN layers\n",
    "        node_state = torch.cat(node_state_list, dim=-1)           # Shape: (batch_size, m, hidR * n_layer)\n",
    "\n",
    "        # Concatenate initial features and GNN outputs\n",
    "        node_state = torch.cat([node_state, feat_emb], dim=-1)    # Shape: (batch_size, m, hidR * n_layer + hidR)\n",
    "\n",
    "        # Step 7: Prediction\n",
    "        res = self.output(node_state)                              # Shape: (batch_size, m, num_timesteps_output)\n",
    "        res = res.transpose(1, 2)                                   # Shape: (batch_size, num_timesteps_output, m)\n",
    "        \n",
    "        print(f\"Shape of X: {X.shape}\")\n",
    "        print(f\"Shape of X_reshaped: {X_reshaped.shape}\")\n",
    "        print(f\"Shape of temp_emb: {temp_emb.shape}\")\n",
    "        print(f\"Shape of attn: {attn.shape}\")\n",
    "\n",
    "\n",
    "        return res  # Predicted covidOccupiedMVBeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique latitudes: [52.1766 51.4923 52.7269 54.5378 53.8981 51.4341 50.8112]\n",
      "Unique longitudes: [ 0.425889 -0.30866  -1.45821  -2.18039  -2.65755  -0.96957  -3.63343 ]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "csv_path = '../data/merged_nhs_covid_data.csv'  # Adjust this path if necessary\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"The specified CSV file does not exist: {csv_path}\")\n",
    "\n",
    "data = pd.read_csv(csv_path, parse_dates=['date'])\n",
    "data = load_and_correct_data(data, REFERENCE_COORDINATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in dataset: 875\n"
     ]
    }
   ],
   "source": [
    "dataset = NHSRegionDataset(data, num_timesteps_input=num_timesteps_input, num_timesteps_output=num_timesteps_output)\n",
    "print(f\"Total samples in dataset: {len(dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix:\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 0., 1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Compute adjacency matrix\n",
    "regions = dataset.regions.tolist()\n",
    "latitudes = [data[data['areaName'] == region]['latitude'].iloc[0] for region in regions]\n",
    "longitudes = [data[data['areaName'] == region]['longitude'].iloc[0] for region in regions]\n",
    "adj = compute_geographic_adjacency(regions, latitudes, longitudes).to(device)\n",
    "print(\"Adjacency matrix:\")\n",
    "print(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EpiGNN model\n",
    "model = EpiGNN(\n",
    "    num_nodes=num_nodes,\n",
    "    num_features=num_features,\n",
    "    num_timesteps_input=num_timesteps_input,\n",
    "    num_timesteps_output=num_timesteps_output,\n",
    "    k=k,\n",
    "    hidA=hidA,\n",
    "    hidR=hidR,\n",
    "    hidP=hidP,\n",
    "    n_layer=n_layer,\n",
    "    dropout=dropout,\n",
    "    device=device\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 612\n",
      "Validation samples: 131\n",
      "Test samples: 132\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training, validation, and test sets\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(RANDOM_SEED)\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn shape before t_enc: torch.Size([32, 7, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x7 and 1x40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m batch_size_current \u001b[38;5;241m=\u001b[39m batch_X\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m batch_adj \u001b[38;5;241m=\u001b[39m adj\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(batch_size_current, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: (batch_size, m, m)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_adj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred, batch_Y)\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/py_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 260\u001b[0m, in \u001b[0;36mEpiGNN.forward\u001b[0;34m(self, X, adj, states, dynamic_adj, index)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Step 3: Generate local transmission risk encoding\u001b[39;00m\n\u001b[1;32m    259\u001b[0m d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(adj, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)            \u001b[38;5;66;03m# Shape: (batch_size, 1, m)\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m s_enc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms_enc\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m                             \u001b[38;5;66;03m# Shape: (batch_size, m, hidR)\u001b[39;00m\n\u001b[1;32m    261\u001b[0m s_enc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_layer(s_enc)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Step 4: Three embedding fusion\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/py_env/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x7 and 1x40)"
     ]
    }
   ],
   "source": [
    "# Training loop with validation and checkpointing\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_patience = 10\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for batch_X, batch_Y in train_loader:\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Expand adjacency matrix to include batch dimension\n",
    "        batch_size_current = batch_X.size(0)\n",
    "        batch_adj = adj.unsqueeze(0).repeat(batch_size_current, 1, 1)  # Shape: (batch_size, m, m)\n",
    "        \n",
    "        pred = model(batch_X, batch_adj)\n",
    "        loss = criterion(pred, batch_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_Y in val_loader:\n",
    "            batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "            \n",
    "            # Expand adjacency matrix to include batch dimension\n",
    "            batch_size_current = batch_X.size(0)\n",
    "            batch_adj = adj.unsqueeze(0).repeat(batch_size_current, 1, 1)  # Shape: (batch_size, m, m)\n",
    "            \n",
    "            pred = model(batch_X, batch_adj)\n",
    "            loss = criterion(pred, batch_Y)\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Checkpointing\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'best_epignn_adapted_model.pth')\n",
    "        print(\"Model checkpoint saved.\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Unique latitudes: [52.1766 51.4923 52.7269 54.5378 53.8981 51.4341 50.8112]\n",
      "Unique longitudes: [ 0.425889 -0.30866  -1.45821  -2.18039  -2.65755  -0.96957  -3.63343 ]\n",
      "Total samples in dataset: 875\n",
      "Adjacency matrix:\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 0., 1., 1.]], device='cuda:0')\n",
      "Training samples: 612\n",
      "Validation samples: 131\n",
      "Test samples: 132\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (224x120 and 80x7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 470\u001b[0m\n\u001b[1;32m    467\u001b[0m batch_size_current \u001b[38;5;241m=\u001b[39m batch_X\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    468\u001b[0m batch_adj \u001b[38;5;241m=\u001b[39m adj\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(batch_size_current, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 470\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_adj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred, batch_Y)\n\u001b[1;32m    472\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/py_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 396\u001b[0m, in \u001b[0;36mEpiGNN.forward\u001b[0;34m(self, X, adj, states, dynamic_adj, index)\u001b[0m\n\u001b[1;32m    393\u001b[0m node_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([node_state, feat_emb], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (batch_size, m, hidR*(n_layer+1))\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# Final prediction\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_state\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (batch_size, m, num_timesteps_output)\u001b[39;00m\n\u001b[1;32m    397\u001b[0m res \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)    \u001b[38;5;66;03m# (batch_size, num_timesteps_output, m)\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/py_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/py_env/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (224x120 and 80x7)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Parameter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Ensure reproducibility across runs\n",
    "RANDOM_SEED = 123\n",
    "def seed_torch(seed=RANDOM_SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch()\n",
    "\n",
    "# Select device for computations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "########################################\n",
    "# Hyperparameters\n",
    "########################################\n",
    "num_nodes = 7\n",
    "num_features = 5  # features: [new_confirmed, new_deceased, newAdmissions, hospitalCases, covidOccupiedMVBeds]\n",
    "num_timesteps_input = 14\n",
    "num_timesteps_output = 7\n",
    "k = 8\n",
    "hidA = 64\n",
    "hidR = 40\n",
    "hidP = 1\n",
    "n_layer = 2\n",
    "dropout = 0.5\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "threshold_distance = 300  # km threshold for considering adjacency\n",
    "\n",
    "########################################\n",
    "# Reference coordinates for correction\n",
    "########################################\n",
    "REFERENCE_COORDINATES = {\n",
    "    \"East of England\": (52.1766, 0.425889),\n",
    "    \"Midlands\": (52.7269, -1.458210),\n",
    "    \"London\": (51.4923, -0.308660),\n",
    "    \"South East\": (51.4341, -0.969570),\n",
    "    \"South West\": (50.8112, -3.633430),\n",
    "    \"North West\": (53.8981, -2.657550),\n",
    "    \"North East and Yorkshire\": (54.5378, -2.180390),\n",
    "}\n",
    "\n",
    "########################################\n",
    "# Data Loading and Preprocessing\n",
    "########################################\n",
    "def load_and_correct_data(data, reference_coordinates):\n",
    "    # Correct geographic coordinates to ensure consistency\n",
    "    for region, coords in reference_coordinates.items():\n",
    "        data.loc[data['areaName'] == region, ['latitude', 'longitude']] = coords\n",
    "\n",
    "    # Diagnostic printouts for verification\n",
    "    print(\"Unique latitudes:\", data['latitude'].unique())\n",
    "    print(\"Unique longitudes:\", data['longitude'].unique())\n",
    "\n",
    "    return data\n",
    "\n",
    "class NHSRegionDataset(Dataset):\n",
    "    def __init__(self, data, num_timesteps_input, num_timesteps_output, transform=None):\n",
    "        self.data = data.copy()\n",
    "        self.num_timesteps_input = num_timesteps_input\n",
    "        self.num_timesteps_output = num_timesteps_output\n",
    "        self.transform = transform\n",
    "\n",
    "        # Sort data chronologically by region\n",
    "        self.data.sort_values(['areaName', 'date'], inplace=True)\n",
    "        self.regions = self.data['areaName'].unique()\n",
    "        self.num_nodes = len(self.regions)\n",
    "        self.region_to_idx = {region: idx for idx, region in enumerate(self.regions)}\n",
    "        self.data['region_idx'] = self.data['areaName'].map(self.region_to_idx)\n",
    "\n",
    "        self.features = ['new_confirmed', 'new_deceased', 'newAdmissions', 'hospitalCases', 'covidOccupiedMVBeds']\n",
    "\n",
    "        # Pivot to create time-series: index=date, columns=(feature, region_idx)\n",
    "        self.pivot = self.data.pivot(index='date', columns='region_idx', values=self.features)\n",
    "        self.pivot.ffill(inplace=True)\n",
    "        self.pivot.fillna(0, inplace=True)\n",
    "\n",
    "        # Reshape into (num_dates, num_nodes, num_features)\n",
    "        self.feature_array = self.pivot.values\n",
    "        self.num_features = len(self.features)\n",
    "        self.num_dates = self.feature_array.shape[0]\n",
    "        self.feature_array = self.feature_array.reshape(self.num_dates, self.num_nodes, self.num_features)\n",
    "\n",
    "        # Validate population consistency\n",
    "        populations = self.data.groupby('areaName')['population'].unique()\n",
    "        inconsistent_pop = populations[populations.apply(len) > 1]\n",
    "        if not inconsistent_pop.empty:\n",
    "            raise ValueError(f\"Inconsistent population values in regions: {inconsistent_pop.index.tolist()}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_dates - self.num_timesteps_input - self.num_timesteps_output + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.feature_array[idx:idx + self.num_timesteps_input]  # (num_timesteps_input, num_nodes, num_features)\n",
    "        Y = self.feature_array[idx + self.num_timesteps_input:idx + self.num_timesteps_input + self.num_timesteps_output, :, 4]\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "            Y = self.transform(Y)\n",
    "\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "def compute_geographic_adjacency(regions, latitudes, longitudes, threshold=threshold_distance):\n",
    "    # Compute adjacency based on geographical proximity using haversine distance\n",
    "    def haversine(lat1, lon1, lat2, lon2):\n",
    "        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2\n",
    "        c = 2 * asin(sqrt(a))\n",
    "        r = 6371  # Earth radius in km\n",
    "        return c * r\n",
    "\n",
    "    num_nodes = len(regions)\n",
    "    adj_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i == j:\n",
    "                adj_matrix[i][j] = 1\n",
    "            elif adj_matrix[i][j] == 0:\n",
    "                distance = haversine(latitudes[i], longitudes[i], latitudes[j], longitudes[j])\n",
    "                if distance <= threshold:\n",
    "                    adj_matrix[i][j] = 1\n",
    "                    adj_matrix[j][i] = 1\n",
    "    return torch.tensor(adj_matrix, dtype=torch.float32)\n",
    "\n",
    "def getLaplaceMat(batch_size, m, adj):\n",
    "    # Compute Laplacian for graph convolution\n",
    "    i_mat = torch.eye(m).to(adj.device).unsqueeze(0).expand(batch_size, m, m)\n",
    "    o_mat = torch.ones(m).to(adj.device).unsqueeze(0).expand(batch_size, m, m)\n",
    "    adj = torch.where(adj > 0, o_mat, adj)\n",
    "\n",
    "    d_mat_out = torch.sum(adj, dim=2)\n",
    "    d_mat = d_mat_out.unsqueeze(2) + 1e-12\n",
    "    d_mat = torch.pow(d_mat, -1)\n",
    "    d_mat = i_mat * d_mat\n",
    "\n",
    "    laplace_mat = torch.bmm(d_mat, adj)\n",
    "    return laplace_mat\n",
    "\n",
    "########################################\n",
    "# Model Definition\n",
    "########################################\n",
    "class GraphConvLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvLayer, self).__init__()\n",
    "        self.weight = Parameter(torch.Tensor(in_features, out_features))\n",
    "        self.act = nn.ELU()\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "            stdv = 1.0 / math.sqrt(out_features)\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, feature, adj):\n",
    "        # feature: (batch_size, m, in_features)\n",
    "        support = torch.matmul(feature, self.weight)      # (batch_size, m, out_features)\n",
    "        output = torch.matmul(adj, support)               # (batch_size, m, out_features)\n",
    "        if self.bias is not None:\n",
    "            return self.act(output + self.bias)\n",
    "        else:\n",
    "            return self.act(output)\n",
    "\n",
    "class GraphLearner(nn.Module):\n",
    "    def __init__(self, hidden_dim, tanhalpha=1):\n",
    "        super(GraphLearner, self).__init__()\n",
    "        self.hid = hidden_dim\n",
    "        self.linear1 = nn.Linear(self.hid, self.hid)\n",
    "        self.linear2 = nn.Linear(self.hid, self.hid)\n",
    "        self.alpha = tanhalpha\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        # embedding: (batch_size, m, hidR)\n",
    "        nodevec1 = torch.tanh(self.alpha * self.linear1(embedding))\n",
    "        nodevec2 = torch.tanh(self.alpha * self.linear2(embedding))\n",
    "\n",
    "        # Learn adjacency structure\n",
    "        adj = torch.bmm(nodevec1, nodevec2.transpose(1, 2)) - torch.bmm(nodevec2, nodevec1.transpose(1, 2))\n",
    "        adj = self.alpha * adj\n",
    "        adj = torch.relu(torch.tanh(adj))\n",
    "        return adj\n",
    "\n",
    "class ConvBranch(nn.Module):\n",
    "    def __init__(self, m, in_channels, out_channels, kernel_size, dilation_factor=2, hidP=1, isPool=True):\n",
    "        super(ConvBranch, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, 1), dilation=(dilation_factor, 1))\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.isPool = isPool\n",
    "        if self.isPool and hidP is not None:\n",
    "            self.pooling = nn.AdaptiveMaxPool2d((hidP, m))\n",
    "        self.activate = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, in_channels, T, m)\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        if self.isPool and hasattr(self, 'pooling'):\n",
    "            x = self.pooling(x)\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1, x.size(-1))  # (batch_size, out_channels * hidP?, m)\n",
    "        x = self.activate(x)\n",
    "        return x\n",
    "\n",
    "class RegionAwareConv(nn.Module):\n",
    "    def __init__(self, nfeat, P, m, k, hidP, dilation_factor=2):\n",
    "        super(RegionAwareConv, self).__init__()\n",
    "        self.conv_l1 = ConvBranch(m=m, in_channels=nfeat, out_channels=k, kernel_size=3, dilation_factor=1, hidP=hidP)\n",
    "        self.conv_l2 = ConvBranch(m=m, in_channels=nfeat, out_channels=k, kernel_size=5, dilation_factor=1, hidP=hidP)\n",
    "        self.conv_p1 = ConvBranch(m=m, in_channels=nfeat, out_channels=k, kernel_size=3, dilation_factor=dilation_factor, hidP=hidP)\n",
    "        self.conv_p2 = ConvBranch(m=m, in_channels=nfeat, out_channels=k, kernel_size=5, dilation_factor=dilation_factor, hidP=hidP)\n",
    "        self.conv_g = ConvBranch(m=m, in_channels=nfeat, out_channels=k, kernel_size=P, dilation_factor=1, hidP=None, isPool=False)\n",
    "        self.activate = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, num_features, P, m)\n",
    "        # Extract local features\n",
    "        x_l1 = self.conv_l1(x)\n",
    "        x_l2 = self.conv_l2(x)\n",
    "        x_local = torch.cat([x_l1, x_l2], dim=1)\n",
    "\n",
    "        # Extract periodic features\n",
    "        x_p1 = self.conv_p1(x)\n",
    "        x_p2 = self.conv_p2(x)\n",
    "        x_period = torch.cat([x_p1, x_p2], dim=1)\n",
    "\n",
    "        # Extract global features\n",
    "        x_global = self.conv_g(x)\n",
    "\n",
    "        # Concatenate all features\n",
    "        x = torch.cat([x_local, x_period, x_global], dim=1)\n",
    "        x = self.activate(x)\n",
    "        return x\n",
    "\n",
    "class EpiGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    EpiGNN: A GNN-based model for epidemiological forecasting of hospital bed usage.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 num_nodes, \n",
    "                 num_features, \n",
    "                 num_timesteps_input,\n",
    "                 num_timesteps_output, \n",
    "                 k=8, \n",
    "                 hidA=64, \n",
    "                 hidR=40, \n",
    "                 hidP=1, \n",
    "                 n_layer=2, \n",
    "                 dropout=0.5, \n",
    "                 device='cpu'):\n",
    "        super(EpiGNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.m = num_nodes\n",
    "        self.w = num_timesteps_input\n",
    "        self.hidR = hidR\n",
    "        self.hidA = hidA\n",
    "        self.hidP = hidP\n",
    "        self.k = k\n",
    "        self.n = n_layer\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "        # Backbone for feature embedding\n",
    "        self.backbone = RegionAwareConv(nfeat=num_features, P=self.w, m=self.m, k=self.k, hidP=self.hidP)\n",
    "\n",
    "        # Global transmission risk encoding\n",
    "        self.WQ = nn.Linear(self.hidR, self.hidA)\n",
    "        self.WK = nn.Linear(self.hidR, self.hidA)\n",
    "        self.t_enc = nn.Linear(1, self.hidR)\n",
    "\n",
    "        # Local transmission risk encoding\n",
    "        # s_enc expects (batch_size, m, 1) as input -> produce (batch_size, m, hidR)\n",
    "        self.s_enc = nn.Linear(1, self.hidR)\n",
    "\n",
    "        # External parameters (optional)\n",
    "        self.external_parameter = nn.Parameter(torch.FloatTensor(self.m, self.m), requires_grad=True)\n",
    "        nn.init.xavier_uniform_(self.external_parameter)\n",
    "\n",
    "        # Graph Generation and GCN\n",
    "        self.d_gate = nn.Parameter(torch.FloatTensor(self.m, self.m), requires_grad=True)\n",
    "        nn.init.xavier_uniform_(self.d_gate)\n",
    "        self.graphGen = GraphLearner(self.hidR)\n",
    "        self.GNNBlocks = nn.ModuleList([GraphConvLayer(in_features=self.hidR, out_features=self.hidR) for _ in range(self.n)])\n",
    "\n",
    "        # Prediction layer\n",
    "        self.output = nn.Linear(self.hidR * 2, num_timesteps_output)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                stdv = 1.0 / math.sqrt(p.size(0))\n",
    "                p.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, X, adj, states=None, dynamic_adj=None, index=None):\n",
    "        # X: (batch_size, T, m, F)\n",
    "        # Permute X to (batch_size, F, T, m) for backbone\n",
    "        adj = adj.bool().float()\n",
    "        batch_size = X.size(0)\n",
    "\n",
    "        if adj.dim() == 2:\n",
    "            adj = adj.unsqueeze(0).expand(batch_size, self.m, self.m)\n",
    "\n",
    "        X_reshaped = X.permute(0, 3, 1, 2)  # (batch_size, F, T, m)\n",
    "        temp_emb = self.backbone(X_reshaped)  # (batch_size, k*..., m) after merging, final shape: (batch_size, hidR, m)\n",
    "\n",
    "        # Ensure temp_emb is (batch_size, m, hidR)\n",
    "        temp_emb = temp_emb.permute(0, 2, 1)  # (batch_size, m, hidR)\n",
    "\n",
    "        # Global transmission encoding\n",
    "        query = self.dropout_layer(self.WQ(temp_emb))  # (batch_size, m, hidA)\n",
    "        key = self.dropout_layer(self.WK(temp_emb))    # (batch_size, m, hidA)\n",
    "\n",
    "        attn = torch.bmm(query, key.transpose(1, 2))   # (batch_size, m, m)\n",
    "        attn = F.normalize(attn, dim=-1, p=2, eps=1e-12)\n",
    "        attn = torch.sum(attn, dim=-1, keepdim=True)   # (batch_size, m, 1)\n",
    "        t_enc = self.dropout_layer(self.t_enc(attn))   # (batch_size, m, hidR)\n",
    "\n",
    "        # Local transmission risk encoding\n",
    "        # Ensure d is (batch_size, m, 1)\n",
    "        d = torch.sum(adj, dim=1).unsqueeze(2)  # (batch_size, m, 1)\n",
    "        s_enc = self.dropout_layer(self.s_enc(d))  # (batch_size, m, hidR)\n",
    "\n",
    "        # Fusion of embeddings\n",
    "        feat_emb = temp_emb + t_enc + s_enc  # (batch_size, m, hidR)\n",
    "\n",
    "        # Optional external resource integration\n",
    "        if self.external_parameter is not None and index is not None:\n",
    "            batch_ext = []\n",
    "            zeros_mt = torch.zeros((self.m, self.m)).to(adj.device)\n",
    "            for i in range(batch_size):\n",
    "                offset = 20\n",
    "                if i - offset >= 0:\n",
    "                    idx = i - offset\n",
    "                    batch_ext.append(self.external_parameter[index[i], :, :].unsqueeze(0))\n",
    "                else:\n",
    "                    batch_ext.append(zeros_mt.unsqueeze(0))\n",
    "            extra_info = torch.cat(batch_ext, dim=0)\n",
    "            external_info = F.relu(torch.mul(self.external_parameter, extra_info))\n",
    "        else:\n",
    "            external_info = 0\n",
    "\n",
    "        # Graph learning\n",
    "        d_mat = torch.bmm(torch.sum(adj, dim=1).unsqueeze(2), torch.sum(adj, dim=1).unsqueeze(1)) # (batch_size, m, m)\n",
    "        d_mat = torch.sigmoid(torch.mul(self.d_gate, d_mat))\n",
    "        spatial_adj = torch.mul(d_mat, adj)\n",
    "        learned_adj = self.graphGen(feat_emb)\n",
    "\n",
    "        if external_info != 0:\n",
    "            adj = learned_adj + spatial_adj + external_info\n",
    "        else:\n",
    "            adj = learned_adj + spatial_adj\n",
    "\n",
    "        laplace_adj = getLaplaceMat(batch_size, self.m, adj)\n",
    "\n",
    "        # GNN layers\n",
    "        node_state = feat_emb\n",
    "        node_state_list = []\n",
    "        for layer in self.GNNBlocks:\n",
    "            node_state = self.dropout_layer(layer(node_state, laplace_adj))\n",
    "            node_state_list.append(node_state)\n",
    "\n",
    "        node_state = torch.cat(node_state_list, dim=-1) # (batch_size, m, hidR * n_layer)\n",
    "        node_state = torch.cat([node_state, feat_emb], dim=-1) # (batch_size, m, hidR*(n_layer+1))\n",
    "\n",
    "        # Final prediction\n",
    "        res = self.output(node_state) # (batch_size, m, num_timesteps_output)\n",
    "        res = res.transpose(1, 2)    # (batch_size, num_timesteps_output, m)\n",
    "        return res\n",
    "\n",
    "########################################\n",
    "# Data Loading and Training\n",
    "########################################\n",
    "csv_path = '../data/merged_nhs_covid_data.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"The specified CSV file does not exist: {csv_path}\")\n",
    "\n",
    "data = pd.read_csv(csv_path, parse_dates=['date'])\n",
    "data = load_and_correct_data(data, REFERENCE_COORDINATES)\n",
    "\n",
    "dataset = NHSRegionDataset(data, num_timesteps_input=num_timesteps_input, num_timesteps_output=num_timesteps_output)\n",
    "print(f\"Total samples in dataset: {len(dataset)}\")\n",
    "\n",
    "regions = dataset.regions.tolist()\n",
    "latitudes = [data[data['areaName'] == region]['latitude'].iloc[0] for region in regions]\n",
    "longitudes = [data[data['areaName'] == region]['longitude'].iloc[0] for region in regions]\n",
    "\n",
    "adj = compute_geographic_adjacency(regions, latitudes, longitudes).to(device)\n",
    "print(\"Adjacency matrix:\")\n",
    "print(adj)\n",
    "\n",
    "model = EpiGNN(\n",
    "    num_nodes=num_nodes,\n",
    "    num_features=num_features,\n",
    "    num_timesteps_input=num_timesteps_input,\n",
    "    num_timesteps_output=num_timesteps_output,\n",
    "    k=k,\n",
    "    hidA=hidA,\n",
    "    hidR=hidR,\n",
    "    hidP=hidP,\n",
    "    n_layer=n_layer,\n",
    "    dropout=dropout,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(RANDOM_SEED)\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_patience = 10\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for batch_X, batch_Y in train_loader:\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_size_current = batch_X.size(0)\n",
    "        batch_adj = adj.unsqueeze(0).repeat(batch_size_current, 1, 1)\n",
    "\n",
    "        pred = model(batch_X, batch_adj)\n",
    "        loss = criterion(pred, batch_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_Y in val_loader:\n",
    "            batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "            batch_size_current = batch_X.size(0)\n",
    "            batch_adj = adj.unsqueeze(0).repeat(batch_size_current, 1, 1)\n",
    "\n",
    "            pred = model(batch_X, batch_adj)\n",
    "            loss = criterion(pred, batch_Y)\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'best_epignn_adapted_model.pth')\n",
    "        print(\"Model checkpoint saved.\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load('best_epignn_adapted_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "all_preds = []\n",
    "all_actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_Y in test_loader:\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "        batch_size_current = batch_X.size(0)\n",
    "        batch_adj = adj.unsqueeze(0).repeat(batch_size_current, 1, 1)\n",
    "\n",
    "        pred = model(batch_X, batch_adj)\n",
    "        loss = criterion(pred, batch_Y)\n",
    "        test_loss += loss.item()\n",
    "        all_preds.append(pred.cpu())\n",
    "        all_actuals.append(batch_Y.cpu())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "# Concatenate predictions and actual values\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "all_actuals = torch.cat(all_actuals, dim=0)\n",
    "\n",
    "# Visualize predictions vs. actuals for a few samples\n",
    "num_plots = 3\n",
    "for i in range(min(num_plots, all_preds.size(0))):\n",
    "    sample_pred = all_preds[i].numpy()\n",
    "    sample_actual = all_actuals[i].numpy()\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for node_idx, region in enumerate(regions):\n",
    "        plt.plot(range(num_timesteps_output), sample_actual[:, node_idx], label=f'Actual - {region}')\n",
    "        plt.plot(range(num_timesteps_output), sample_pred[:, node_idx], '--', label=f'Predicted - {region}')\n",
    "\n",
    "    plt.xlabel('Future Timestep')\n",
    "    plt.ylabel('COVID Occupied MV Beds')\n",
    "    plt.title(f'Sample {i+1}: Predictions vs Actual')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.state_dict(), 'epignn_adapted_model_final.pth')\n",
    "print(\"Final model saved as 'epignn_adapted_model_final.pth'.\")\n",
    "\n",
    "# Compute additional metrics (MAE, R²)\n",
    "preds_flat = all_preds.view(-1, num_nodes).numpy()\n",
    "actuals_flat = all_actuals.view(-1, num_nodes).numpy()\n",
    "\n",
    "mae_per_node = mean_absolute_error(actuals_flat, preds_flat, multioutput='raw_values')\n",
    "r2_per_node = r2_score(actuals_flat, preds_flat, multioutput='raw_values')\n",
    "\n",
    "for idx, region in enumerate(regions):\n",
    "    print(f\"Region: {region}, MAE: {mae_per_node[idx]:.4f}, R2 Score: {r2_per_node[idx]:.4f}\")\n",
    "\n",
    "# Visualize learned adjacency matrix for a test sample\n",
    "example_X, _ = next(iter(test_loader))\n",
    "example_X = example_X.to(device)\n",
    "with torch.no_grad():\n",
    "    batch_size_current = example_X.size(0)\n",
    "    batch_adj = adj.unsqueeze(0).repeat(batch_size_current, 1, 1)\n",
    "    example_pred = model(example_X, batch_adj)\n",
    "\n",
    "# Compute learned adjacency from the backbone embeddings\n",
    "learned_adj = model.graphGen(model.backbone(example_X.permute(0,3,1,2))).cpu().numpy()[0]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(learned_adj, annot=True, fmt=\".2f\", cmap='viridis', xticklabels=regions, yticklabels=regions)\n",
    "plt.title('Learned Adjacency Matrix (Test Sample)')\n",
    "plt.xlabel('Regions')\n",
    "plt.ylabel('Regions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
